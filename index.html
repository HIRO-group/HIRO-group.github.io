---
type: home
subtypes: [news]
pagelimit: 20
subtypes: [algorithmic hri and human-ai teaming, control and artificial skin,learning and modeling]
---

{% include video.html url="//www.youtube.com/embed/I5gXYuJj62k" margin-bottom="40px" padding-bottom="52%" max-width="100%" %}

Welcome to the **H**uman **I**nteraction and **RO**botics [**HIRO**] Group!! Our work lies at the intersection of _Artificial Intelligence_, _Robotics_, and _Human-AI Teaming_ with the goal of **building robot systems that enable close, natural, and extended cooperation with humans**{:.color-banner}.

Our work is ambitious, impactful, and often goes against the grain. We work on what's hard, and _we focus on important problems with potential for positive societal impact_. We have built a large and diverse group that attracts top talent from leading institutions and **consistently produces award-winning research**. Many of our students have gone on to secure highly competitive fellowships and leadership roles in academia and industry.

Our group is within the [Department of Computer Science](https://cs.colorado.edu) in the [College of Engineering and Applied Science](https://www.colorado.edu/engineering) at [CU Boulder](https://www.colorado.edu).
If you want to learn more about our research and you would like involved with the lab, feel free to stop by during our weekly meetings!! For _{{ site.meetings.semester }}_, we will be holding group meetings in **{{ site.meetings.location }}**{:.color-banner}{{ site.meetings.note }}.

The HIRO Group is funded by the following organizations:

<div class="funder-logos">
    <img src="/img/logos/nsf.png">
    <img src="/img/logos/nasa.png">
    <img src="/img/logos/arl.png">
    <img src="/img/logos/onr.png">
    <img src="/img/logos/apple.png">
</div>

## Research
---

**Our research is both human-inspired and human-centered**. We believe that to build truly capable and general-purpose robots, we must look at people not just as users, but as models of intelligence. Two pillars of human cognition guide our work: **our ability to learn through embodied interaction with the physical world**{:.color-banner}, and **our capacity for social intelligence in complex, cooperative settings**{:.color-banner}. These principles motivate the two core research threads in the lab: Embodied Intelligence and Sensorimotor Learning, and Social Intelligence and Algorithmic Human-Robot Interaction.

For more details on our research efforts, please [visit our list of publications]({{ site.baseurl }}{% link publications.html %}).

### Embodied Intelligence and Sensorimotor Learning
---

Point of Contact: [Caleb Escobedo]({% post_url people/2019-10-10-caleb %}), [Anuj Pasricha]({% post_url people/2019-10-13-anuj %}), [Nataliya Nechyporenko](https://nataliya.dev/), [Gilberto Briscoe-Martinez]({% post_url people/2023-11-15-gilberto %}), [Stéphane Aroca-Ouellette](https://stephao.github.io/), [Joewie J. Koh](https://joewiekoh.com), Yutong Zhang, Jay Vakil

<div class="row">
{% include image.html url="research/roboskin/franka_skin_avoidance.gif" max-width="44%" %}
{% include image.html url="research/planning/robot-reach-169.gif" max-width="44%" %}
</div>

{% comment %}
In this subteam, we focus on ensuring that humans and robots can interact safely by simultaneously developing **novel sensing hardware** and **motion control frameworks**.
The hardware component of this project has led to the development of modular sensor units that can be positioned anywhere on the surface of a robot manipulator to gather information about the robot’s immediate surroundings.
Using the information provided by our sensor units, we have developed a control framework that allows robot manipulators to anticipate, detect, and react to external contact that could otherwise be harmful.
[[Read More]]({{ site.url }}/subteam/control-artificial-skin)
{% endcomment %}

### Social Intelligence and Human-Robot Collaboration
---

Point of Contact: [Jake Brawer](https://jakebrawer.com/), [Kaleb Bishop](https://kalebishop.github.io/), [Clare Lohrmann](https://cmlohrmann.github.io/), [Yi-Shiuan Tung](https://yi-shiuan-tung.github.io/), [Stéphane Aroca-Ouellette](https://stephao.github.io/), Ava Abderezaei, Srikrishna Bangalore Raghu, Chi-Hui Lin, Naren Sigvanadasan

<div class="row">
{% include image.html url="research/algo-social-hri/workspace_opt_169.gif" max-width="66%" %}
{% include image.html url="research/algo-social-hri/multi_robots_gif.gif"  max-width="33.5%" %}
</div>

{% comment %}
Our team aims to advance fundamental robot capabilities for future human-robot scenarios. 
We develop sophisticated robot technologies for human environments, and address challenges in: multimodal motion planning, long-term robot autonomy, non-prehensile manipulation, natural language grounding, and 
cooperative multi-agent reinforcement learning. 
Through these initiatives, we work towards bridging the gap between robotics and artificial intelligence, pushing the boundaries of robotic abilities to improve thir real-world usefulness.
[[Read More]]({{ site.url }}/subteam/learning-modeling-robotics)




The goal of this subteam is to create robot behaviors that make robots more effective teammates and collaborators with humans. We use an interdisciplinary approach, leveraging machine learning, cognitive science, and social psychology to make robots more predictable, legible, and safe around humans. This subteam works with a variety of collaborators to conduct foundational research and run human-subjects studies in-person, online, and in virtual reality to validate these approaches.
[[Read More]]({{ site.url }}/subteam/algorithmic-hri)

<div class="row">
{% include post-sorter.html subtypes="subteams" %}
</div>

{% endcomment %}

## Latest News
---

<div class="row">
{% include post-sorter.html subtype="news" %}
</div>
