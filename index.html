---
type: home
subtypes: [news]
pagelimit: 20
subtypes: [algorithmic hri and human-ai teaming, control and artificial skin,learning and modeling]
---

{% include video.html url="//www.youtube.com/embed/I5gXYuJj62k" margin-bottom="40px" padding-bottom="52%" max-width="100%" %}

Welcome to the **H**uman **I**nteraction and **RO**botics [**HIRO**] Group!! Our work lies at the intersection of _Artificial Intelligence_, _Robotics_, and _Human-AI Teaming_ with the goal of **building robot systems that enable close, natural, and extended cooperation with humans**{:.color-banner}.

Our work is ambitious, impactful, and often goes against the grain. We work on what's hard, and _we focus on important problems with potential for positive societal impact_. We have built a large and diverse group that attracts top talent from leading institutions and **consistently produces award-winning research**. Many of our students have gone on to secure highly competitive fellowships and leadership roles in academia and industry.

Our group is within the [Department of Computer Science](https://cs.colorado.edu) in the [College of Engineering and Applied Science](https://www.colorado.edu/engineering) at [CU Boulder](https://www.colorado.edu).
If you want to learn more about our research and you would like involved with the lab, feel free to stop by during our weekly meetings!! For _{{ site.meetings.semester }}_, we will be holding group meetings in **{{ site.meetings.location }}**{:.color-banner}{{ site.meetings.note }}.

The HIRO Group is funded by the following organizations:

<div class="funder-logos">
    <img src="/img/logos/nsf.png">
    <img src="/img/logos/nasa.png">
    <img src="/img/logos/arl.png">
    <img src="/img/logos/onr.png">
    <img src="/img/logos/apple.png">
</div>

## Research
---

**Our research is both human-inspired and human-centered**. We believe that to build truly capable and general-purpose robots, we must look at people not just as users, but as models of intelligence. Two pillars of human cognition guide our work: **our ability to learn through embodied interaction with the physical world**{:.color-banner}, and **our capacity for social intelligence in complex, cooperative settings**{:.color-banner}. These principles motivate the two core research threads in the lab: Embodied Intelligence and Sensorimotor Learning, and Social Intelligence and Algorithmic Human-Robot Interaction.

For more details on our research efforts, please [visit our list of publications]({{ site.baseurl }}{% link publications.html %}).

{% include image.html url="HIRO_research_website.svg" max-width="80%" %}

### Embodied Intelligence and Sensorimotor Learning
---

We develop robots that can operate safely and effectively in cluttered, dynamic, and contact-rich environments. Our work treats _contact as a structured source of information_, not as failure, and builds sensing and planning capabilities around this principle. From scalable, whole-body skins to algorithms that intentionally use contact to achieve goals, we equip robots to interact with the physical world through feedback and adaptation. 

<div class="row">
{% include image.html url="research/roboskin/franka_skin_avoidance.gif" max-width="44%" %}
{% include image.html url="research/planning/robot-reach-169.gif" max-width="44%" %}
</div>

In the future, we aim to formalize the concept of **morphological intelligence**, enabling robots to reason about their own bodies to select robust and efficient strategies in complex scenarios. This approach will expand the range of tasks robots can perform and improve resilience to uncertainty and partial failure.

*Point of Contact:* [Caleb Escobedo]({% post_url people/2019-10-10-caleb %}), [Anuj Pasricha]({% post_url people/2019-10-13-anuj %}), [Nataliya Nechyporenko](https://nataliya.dev/), [Gilberto Briscoe-Martinez]({% post_url people/2023-11-15-gilberto %}), [Stéphane Aroca-Ouellette](https://stephao.github.io/), [Joewie J. Koh](https://joewiekoh.com), Yutong Zhang, Jay Vakil

{% comment %}
In this subteam, we focus on ensuring that humans and robots can interact safely by simultaneously developing **novel sensing hardware** and **motion control frameworks**.
The hardware component of this project has led to the development of modular sensor units that can be positioned anywhere on the surface of a robot manipulator to gather information about the robot's immediate surroundings.
Using the information provided by our sensor units, we have developed a control framework that allows robot manipulators to anticipate, detect, and react to external contact that could otherwise be harmful.
[[Read More]]({{ site.url }}/subteam/control-artificial-skin)
{% endcomment %}

### Social Intelligence and Human-Robot Collaboration
---

We design robots that align with human partners through structured representations, implicit signals, and environment shaping. Our research focuses on creating agents that reason over shared task models, adapt to human strategies without retraining, and communicate intent through predictable motion and environmental cues. Current work shows that these methods improve fluency, trust, and team performance in collaborative settings. 

<div class="row">
{% include image.html url="research/algo-social-hri/workspace_opt_169.gif" max-width="66%" %}
{% include image.html url="research/algo-social-hri/multi_robots_gif.gif"  max-width="33.5%" %}
</div>

In the future, we aim to incorporate models of human expectation directly into trajectory optimization, producing behaviors that are not only functional but also intuitive to humans. This direction enables more effective teamwork in domains such as assistive care, education, and high-stakes decision-making.

*Point of Contact:* [Jake Brawer](https://jakebrawer.com/), [Kaleb Bishop](https://kalebishop.github.io/), [Clare Lohrmann](https://cmlohrmann.github.io/), [Yi-Shiuan Tung](https://yi-shiuan-tung.github.io/), [Stéphane Aroca-Ouellette](https://stephao.github.io/), Ava Abderezaei, Srikrishna Bangalore Raghu, Chi-Hui Lin, Naren Sigvanadasan

{% comment %}
Our team aims to advance fundamental robot capabilities for future human-robot scenarios. 
We develop sophisticated robot technologies for human environments, and address challenges in: multimodal motion planning, long-term robot autonomy, non-prehensile manipulation, natural language grounding, and 
cooperative multi-agent reinforcement learning. 
Through these initiatives, we work towards bridging the gap between robotics and artificial intelligence, pushing the boundaries of robotic abilities to improve thir real-world usefulness.
[[Read More]]({{ site.url }}/subteam/learning-modeling-robotics)




The goal of this subteam is to create robot behaviors that make robots more effective teammates and collaborators with humans. We use an interdisciplinary approach, leveraging machine learning, cognitive science, and social psychology to make robots more predictable, legible, and safe around humans. This subteam works with a variety of collaborators to conduct foundational research and run human-subjects studies in-person, online, and in virtual reality to validate these approaches.
[[Read More]]({{ site.url }}/subteam/algorithmic-hri)

<div class="row">
{% include post-sorter.html subtypes="subteams" %}
</div>

{% endcomment %}

## Latest News
---

<div class="row">
{% include post-sorter.html subtype="news" %}
</div>
