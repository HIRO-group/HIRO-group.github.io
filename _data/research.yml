#  - project: 
#   img: /img/
#   blurb: ""
#   webpage:
#   publications:
#     - title: 
#       authors:
#       date: 
#       venue: 
#       url:
#   funding:
#     - 

 - project: Light source estimation
   img: /img/light_source_estimation.gif
   blurb: "This effort addresses the problem of determining the location, direction, intensity, and color of the illuminants in a given scene. The problem has a broad range of applications in augmented reality, robust robot perception, and general scene understanding. In our research, we model complex light interactions with a custom path-tracer, capturing the effects of both direct and indirect illumination. Using a physically-based light model not only improves our estimation of the light sources, but will play a critical role in future research in surface property estimation and geometry refinement, ultimately leading to more accurate and complete scene reconstruction systems." 
   publications:
     - title: Multiple Point Light Estimation from Low-Quality 3D Reconstructions
       authors: Mike Kasper, Christoffer Heckman
       date: 2019
       venue: "International Conference on 3D Vision (3DV)"
     - title: Light Source Estimation in Synthetic Images
       authors: Mike Kasper, Nima Keivan, Gabe Sibley, Christoffer Heckman
       date: 2016
       venue: "European Conference on Computer Vision, Virtual/Augmented Reality for Visual Artificial Intelligence Workshop"
       url: "https://link.springer.com/chapter/10.1007/978-3-319-49409-8_72?no-access=true"
   funding:
     - "Toyota grant 33643/1/ECNS20952N: Robust Perception"

 - project: Parkour Cars 
   img: /img/ninja_car/NinjaCarJump1.gif
   blurb: "This project aims to develop high fidelity real-time systems for perception, planning and control of agile vehicles in challenging terrain including jumps and loop-the-loops. The current research is focused on the local planning and control problem. Due to the difficulty of the maneuvers, the planning and control systems must consider the underlying physical model of the vehicle and terrain. This style of simulation-in-the-loop planning enables very accurate prediction and correction of the vehicle state, as well as the ability to learn precise attributes of the underlying physical model."
   publications:
     - title: Terrain Aware Model Predictive Controller for Autonomous Ground Vehicles
       authors: Sina Aghli and Christoffer Heckman
       date: 2017
       venue: "Robotics: Science and Systems, Bridging the Gap in Space Robotics Workshop"
       url: /papers/
     - title: Simulation-in-the-loop for Planning and Model-Predictive Control
       authors: Christoffer Heckman, Nima Keivan, and Gabe Sibley
       date: 2015
       venue: "Robotics: Science and Systems, Realistic, Rapid, and Repeatable Robot Simulation Workshop"
       url: /papers/
   funding:
     - "NSF #1646556. CPS: Synergy: Verified Control of Cooperative Autonomous Vehicles"
     - "DARPA #N65236-16-1-1000. DSO Seedling: Ninja Cars"
     - "Toyota grant 33643/1/ECNS20952N: Robust Perception"

 - project: Referring Expressions for Object Localization
   blurb: "Understanding references to objects based on attributes, spatial relationships, and other descriptive language expands the capability of robots to locate unknown objects (zero-shot learning), find objects in cluttered scenes, and communicate uncertainty with human collaborators. We are collecting a new set of annotations, SUNspot, for the SUNRGB-d scene understanding dataset. Unlike other referring expression datasets, SUNspot will focus on graspable objects in interior scenes accompanied by the depth sensor data and full semantic segmentation from the SUNRGB-d dataset. Using SUNspot, we hope to develop a novel referring expressions system that will improve object localization for use in human-robot interaction."

 - project: "RAMFIS: Representations of Abstract Meaning for Information Synthesis"
   img: /img/RAMFIS_example.png
   blurb: "Humans can readily extract complex information from many different modalities, including spoken and written expressions and information from images and videos, and synthesize it into a coherent whole. This project aims to support automated synthesis of diverse multi-media information sources. // We are proposing a rich, multi-graph Common Semantic Representation (CSR) based on Abstract Meaning Representations (AMRs) embellished with vision and language vector representations and temporal and causal relations between events, and supported by a rich ontology of event and entity types."
   funding:
     - "DARPA Award: FA8750-18-2-0016. AIDA"

 - project: Compass
   blurb: "Compass is a simultaneous localization and mapping (SLAM) pipeline with extensible frontend capability and an optimization backend based on Ceres solver."
   publications:
     - title: 
       authors: Fernando Nobre, Mike Kasper, Christoffer Heckman.
       date: 2017
       venue: IEEE International Conference on Robotics and Automation
       url:
     - title: 
       authors: Fernando Nobre, Christoffer Heckman.
       date: 2016
       venue: International Symposium on Experimental Robotics
       url:
   funding:
     - "DARPA #N65236-16-1-1000. DSO Seedling: Ninja Cars"
     - "Toyota grant 33643/1/ECNS20952N: Robust Perception"

 - project: "MARBLE: Multi-agent Autonomy with RADAR-Based Localization for Exploration"
   img: /img/SubT-overview.jpg
   blurb: "ARPG is a component of team MARBLE, a funded participant in the DARPA Subterranean Challenge. We are providing expertise in autonomy, perception, and navigation. The project kicked off in September 2018 and is ongoing, with competition events in August 2019 onward."
   webpage: http://subtchallenge.com
   funding:
     - "DARPA TTO Subterranean Challenge"
     
- project: "MARBLE - Radar Perception"
  blurb: "This project addresses creating accurate odometry and maps in visually degraded environments using radar and ineratial sensors. The DARPA SubT competition sections off portions of the environment with artificial fog."
  publications:
    - title: Radar-Inertial State Estimation and Mapping for Micro-Aerial Vehicles In Dense Fog
       authors: Andrew Kramer, Shakeeb Ahmad, and Christoffer Heckman
       date: 2020
       venue: International Symposium on Experimental Robotics
     - title: Radar-Inertial Ego-Velocity Estimation for Visually Degraded Environments
       authors: Andrew Kramer, Angel Santamaria-Navarro, Aliakbar Aghamohammadi, and Christoffer Heckman
       date: 2020
       venue: International Conference on Robotics and Automation
  funding:
     - "DARPA TTO Subterranean Challenge"


 - project: "Robotic Perception With Millimeter Wave RADAR"
   blurb: "Investigating methods for millimeter wave RADAR based state estimation, mapping, and more."
   publications:
     - title: Radar-Inertial State Estimation and Mapping for Micro-Aerial Vehicles In Dense Fog
       authors: Andrew Kramer, Shakeeb Ahmad, and Christoffer Heckman
       date: 2020
       venue: International Symposium on Experimental Robotics
     - title: Radar-Inertial Ego-Velocity Estimation for Visually Degraded Environments
       authors: Andrew Kramer, Angel Santamaria-Navarro, Aliakbar Aghamohammadi, and Christoffer Heckman
       date: 2020
       venue: International Conference on Robotics and Automation
   funding:
     - "NASA NSTRF 80NSSC18K1195"

